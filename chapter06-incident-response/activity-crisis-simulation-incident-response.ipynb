{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d99e06e",
   "metadata": {},
   "source": [
    "# Chapter 6 Activity: Crisis Simulation - AI Incident Response\n",
    "\n",
    "## Emergency Response: AI Model Breach at TechCorp\n",
    "\n",
    "**Estimated Time:** 30 minutes  \n",
    "**Learning Objectives:**\n",
    "- Execute an AI-specific incident response plan\n",
    "- Practice automated incident detection and analysis\n",
    "- Implement model isolation and recovery procedures\n",
    "- Generate incident reports and stakeholder communications\n",
    "\n",
    "---\n",
    "\n",
    "## Emergency Scenario\n",
    "\n",
    "**ALERT: CRITICAL AI SECURITY INCIDENT**\n",
    "\n",
    "You are the Lead AI Security Analyst at TechCorp. At 14:30 today, automated monitoring systems detected anomalous behavior in the company's customer recommendation AI model. Initial analysis suggests a potential adversarial attack or data poisoning incident.\n",
    "\n",
    "**Immediate Situation:**\n",
    "- Customer recommendation accuracy has dropped from 94% to 67%\n",
    "- Unusual prediction patterns detected in the last 2 hours\n",
    "- Potential business impact: $50K revenue loss per hour\n",
    "- 100,000+ customers potentially affected\n",
    "\n",
    "**Your Mission:** Lead the incident response team through a structured response to contain, analyze, and recover from this AI security incident.\n",
    "\n",
    "Let's begin the emergency response!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd51873",
   "metadata": {},
   "source": [
    "## Phase 1: Incident Detection and Initial Assessment (5 minutes)\n",
    "\n",
    "First, let's set up our incident response environment and analyze the initial detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for incident response simulation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize incident response system\n",
    "print(\"üö® AI INCIDENT RESPONSE SYSTEM ACTIVATED üö®\")\n",
    "print(f\"Response initiated at: {datetime.now()}\")\n",
    "print(\"Incident ID: INC-2025-0804-001\")\n",
    "print(\"Severity: HIGH\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e21af",
   "metadata": {},
   "source": [
    "### üìã **What Just Happened?**\n",
    "\n",
    "**The output above shows our AI security system has been activated!** Here's what each part means:\n",
    "\n",
    "- **Incident ID**: `INC-2025-0804-001` - A unique identifier for tracking this security incident\n",
    "- **Severity**: `HIGH` - This indicates we have a serious security situation that needs immediate attention\n",
    "- **Timestamp**: The exact time when our monitoring system detected the problem\n",
    "\n",
    "**Why This Matters**: In real-world AI security, having proper incident tracking and immediate severity classification is crucial. This helps security teams prioritize responses and maintain audit trails for compliance and post-incident analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409aaa6",
   "metadata": {},
   "source": [
    "### üéì **What You'll Learn in This Simulation**\n",
    "\n",
    "**You're about to experience a realistic AI security incident from detection to resolution!**\n",
    "\n",
    "**Learning Journey:**\n",
    "1. **üîç Threat Detection** - See how AI systems monitor for security problems\n",
    "2. **üìä Data Analysis** - Learn to interpret performance metrics and anomaly patterns  \n",
    "3. **‚ö° Rapid Response** - Execute containment procedures under time pressure\n",
    "4. **üì¢ Crisis Communication** - Manage stakeholder notifications during incidents\n",
    "5. **üìÑ Documentation** - Create compliance-ready incident reports\n",
    "\n",
    "**Professional Skills You'll Develop:**\n",
    "- Reading AI performance metrics and recognizing attack patterns\n",
    "- Understanding severity classification systems  \n",
    "- Executing incident response procedures\n",
    "- Managing crisis communications across different audiences\n",
    "- Creating professional incident documentation\n",
    "\n",
    "**Real-World Context:**\n",
    "This simulation uses actual techniques from enterprise AI security operations. The procedures, metrics, and documentation you'll see mirror what professionals use to respond to real AI attacks affecting millions of users.\n",
    "\n",
    "**Time Investment**: ~30 minutes for complete simulation\n",
    "**Difficulty Level**: Beginner-friendly with detailed explanations\n",
    "\n",
    "**Ready to begin? Let's start with performance monitoring...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39871fce",
   "metadata": {},
   "source": [
    "### Understanding the Initial Setup\n",
    "\n",
    "The code above initializes our incident response simulation environment. In a real scenario, this would represent:\n",
    "- **Alert System Activation**: Automated monitoring triggers the incident response\n",
    "- **Incident ID Assignment**: Unique identifier for tracking and documentation\n",
    "- **Severity Classification**: Initial assessment based on automated detection\n",
    "- **Library Imports**: Essential tools for data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc40a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic performance data for the last 7 days (168 hours)\n",
    "hours = 168  # 7 days\n",
    "baseline_accuracy = 0.95\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Simulate gradual performance degradation\n",
    "performance_data = []\n",
    "for i in range(hours):\n",
    "    # Create realistic performance degradation pattern\n",
    "    time_factor = i / hours  # 0 to 1 over time\n",
    "    \n",
    "    # Add some randomness but trending downward\n",
    "    noise = np.random.normal(0, 0.02)  # Small random variations\n",
    "    degradation_factor = 0.7 + 0.3 * (1 - time_factor)  # Gradual decline\n",
    "    \n",
    "    accuracy = baseline_accuracy * degradation_factor + noise\n",
    "    accuracy = max(0.5, min(0.99, accuracy))  # Keep realistic bounds\n",
    "    \n",
    "    timestamp = current_time - timedelta(hours=hours-i)\n",
    "    performance_data.append({\n",
    "        'timestamp': timestamp,\n",
    "        'accuracy': accuracy,\n",
    "        'response_time': np.random.uniform(100, 300) * (1 + time_factor),  # Increasing response time\n",
    "        'throughput': np.random.uniform(800, 1200) * (1 - time_factor * 0.3)  # Decreasing throughput\n",
    "    })\n",
    "\n",
    "# Calculate current metrics\n",
    "current_accuracy = performance_data[-1]['accuracy']\n",
    "performance_drop = ((baseline_accuracy - current_accuracy) / baseline_accuracy) * 100\n",
    "\n",
    "print(\"PERFORMANCE DATA GENERATED:\")\n",
    "print(f\"Total data points: {len(performance_data)}\")\n",
    "print(f\"Current accuracy: {current_accuracy:.3f}\")\n",
    "print(f\"Baseline accuracy: {baseline_accuracy:.3f}\")\n",
    "print(f\"Performance drop: {performance_drop:.1f}%\")\n",
    "\n",
    "# Store performance analysis\n",
    "performance_analysis = {\n",
    "    'baseline_accuracy': baseline_accuracy,\n",
    "    'current_accuracy': current_accuracy,\n",
    "    'performance_drop': performance_drop,\n",
    "    'data_points': len(performance_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bebf45",
   "metadata": {},
   "source": [
    "### üìä **Understanding the Performance Data**\n",
    "\n",
    "**This output shows our AI model is experiencing significant problems!** Let's break down what we're seeing:\n",
    "\n",
    "- **Total data points**: 168 (representing 7 days of hourly performance monitoring)\n",
    "- **Current accuracy**: The model's current performance (around 67-73%)\n",
    "- **Baseline accuracy**: What the model should perform at (95%)\n",
    "- **Performance drop**: **~29%** - This is a major red flag! üö®\n",
    "\n",
    "**Critical Insight**: A 29% performance drop is extremely concerning in production AI systems. In real scenarios:\n",
    "- **5-10% drop**: Monitor closely\n",
    "- **10-20% drop**: Investigate immediately  \n",
    "- **20%+ drop**: **INCIDENT RESPONSE REQUIRED**\n",
    "\n",
    "**What This Means**: Our model has degraded from excellent performance (95%) to concerning levels (~70%). This could indicate data poisoning, model drift, or an active attack!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3ea00",
   "metadata": {},
   "source": [
    "### Performance Data Simulation Explained\n",
    "\n",
    "The code above creates a realistic scenario of an AI model under attack:\n",
    "\n",
    "1. **Baseline Performance**: 7 days of normal operation at ~94% accuracy\n",
    "2. **Early Attack Signs**: Gradual degradation to ~92% starting 6 hours ago\n",
    "3. **Severe Attack Impact**: Sharp drop to ~67% in the last 2 hours\n",
    "\n",
    "This pattern is typical of:\n",
    "- **Data poisoning attacks** that gradually corrupt model performance\n",
    "- **Adversarial attacks** that intensify over time\n",
    "- **Model drift** accelerated by malicious inputs\n",
    "\n",
    "In production, this data would come from your model monitoring systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9043ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance trends and classify severity\n",
    "def analyze_performance_trends(performance_data, baseline_accuracy):\n",
    "    \"\"\"Analyze performance trends and determine incident severity\"\"\"\n",
    "    current_accuracy = performance_data[-1]['accuracy']\n",
    "    performance_drop = ((baseline_accuracy - current_accuracy) / baseline_accuracy) * 100\n",
    "    \n",
    "    # Classify severity based on performance degradation\n",
    "    if performance_drop > 30:\n",
    "        severity = \"CRITICAL\"\n",
    "        description = \"Severe performance degradation detected!\"\n",
    "    elif performance_drop > 20:\n",
    "        severity = \"HIGH\"\n",
    "        description = \"Significant performance degradation detected!\"\n",
    "    elif performance_drop > 10:\n",
    "        severity = \"MEDIUM\"\n",
    "        description = \"Moderate performance degradation detected\"\n",
    "    else:\n",
    "        severity = \"LOW\"\n",
    "        description = \"Minor performance variations detected\"\n",
    "    \n",
    "    return {\n",
    "        'current_accuracy': current_accuracy,\n",
    "        'baseline_accuracy': baseline_accuracy,\n",
    "        'performance_drop': performance_drop,\n",
    "        'severity': severity,\n",
    "        'description': description\n",
    "    }\n",
    "\n",
    "print(\"INITIAL SEVERITY ASSESSMENT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get the current accuracy from our most recent performance data\n",
    "current_accuracy = performance_data[-1]['accuracy']\n",
    "print(f\"Current accuracy: {current_accuracy:.3f}\")\n",
    "print(f\"Baseline accuracy: {baseline_accuracy:.3f}\")\n",
    "print(f\"Performance degradation: {performance_drop:.1f}%\")\n",
    "\n",
    "# Classify severity\n",
    "if performance_drop > 30:\n",
    "    severity_level = \"CRITICAL\"\n",
    "    print(f\"\\nCRITICAL: Severe performance degradation detected!\")\n",
    "elif performance_drop > 20:\n",
    "    severity_level = \"HIGH\"\n",
    "    print(f\"\\nHIGH: Significant performance degradation detected!\")\n",
    "elif performance_drop > 10:\n",
    "    severity_level = \"MEDIUM\"\n",
    "    print(f\"\\nMEDIUM: Moderate performance degradation detected\")\n",
    "else:\n",
    "    severity_level = \"LOW\"\n",
    "    print(f\"\\nLOW: Minor performance variations detected\")\n",
    "\n",
    "print(f\"Incident severity classification: {severity_level}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4d36e",
   "metadata": {},
   "source": [
    "### üö® **Severity Classification Explained**\n",
    "\n",
    "**The system has automatically classified this as a HIGH severity incident.** Here's how severity levels work in AI security:\n",
    "\n",
    "**Severity Levels:**\n",
    "- **LOW** (0-10% degradation): Minor performance variations, continue monitoring\n",
    "- **MEDIUM** (10-20% degradation): Moderate issues, standard investigation procedures\n",
    "- **HIGH** (20-30% degradation): **Significant problems, immediate response required**\n",
    "- **CRITICAL** (30%+ degradation): System compromise likely, emergency protocols\n",
    "\n",
    "**Why HIGH Severity?** \n",
    "Our 22-29% performance drop indicates:\n",
    "- Possible data poisoning attack\n",
    "- Model compromise or manipulation\n",
    "- Critical system vulnerability\n",
    "- Potential business impact\n",
    "\n",
    "**Next Steps**: HIGH severity triggers immediate containment procedures to prevent further damage and preserve evidence for forensic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9cfcb",
   "metadata": {},
   "source": [
    "## Phase 2: Automated Threat Analysis (8 minutes)\n",
    "\n",
    "Let's implement our automated incident analysis system to understand the nature of the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf80a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIIncidentAnalyzer:\n",
    "    \"\"\"Advanced AI system incident analysis and threat detection\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.threat_indicators = {\n",
    "            'performance_degradation': False,\n",
    "            'anomaly_detection': False, \n",
    "            'data_drift': False,\n",
    "            'adversarial_attack': False\n",
    "        }\n",
    "    \n",
    "    def analyze_performance_trends(self, performance_data):\n",
    "        \"\"\"Analyze recent performance vs baseline to detect degradation\"\"\"\n",
    "        # Extract accuracy values from the performance data list\n",
    "        accuracies = [data_point['accuracy'] for data_point in performance_data]\n",
    "        \n",
    "        # Get recent 6 hours vs earlier baseline (first 144 hours)\n",
    "        recent_performance = np.mean(accuracies[-6:])  # Last 6 hours\n",
    "        baseline_performance = np.mean(accuracies[:144])  # First 144 hours\n",
    "        \n",
    "        degradation = (baseline_performance - recent_performance) / baseline_performance\n",
    "        degradation_percentage = degradation * 100\n",
    "        \n",
    "        # Check if this constitutes a threat\n",
    "        threat_detected = degradation_percentage > 15  # 15% degradation threshold\n",
    "        self.threat_indicators['performance_degradation'] = threat_detected\n",
    "        \n",
    "        return {\n",
    "            'baseline_avg': baseline_performance,\n",
    "            'recent_avg': recent_performance,\n",
    "            'degradation': degradation,\n",
    "            'degradation_percentage': degradation_percentage,\n",
    "            'threat_detected': threat_detected\n",
    "        }\n",
    "\n",
    "# Create analyzer instance\n",
    "analyzer = AIIncidentAnalyzer()\n",
    "\n",
    "print(\"PERFORMANCE TREND ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Analyze performance trends\n",
    "perf_analysis = analyzer.analyze_performance_trends(performance_data)\n",
    "print(f\"Baseline average: {perf_analysis['baseline_avg']:.3f}\")\n",
    "print(f\"Recent average: {perf_analysis['recent_avg']:.3f}\")\n",
    "print(f\"Performance degradation: {perf_analysis['degradation_percentage']:.1f}%\")\n",
    "\n",
    "if perf_analysis['threat_detected']:\n",
    "    print(\"THREAT DETECTED: Significant performance degradation\")\n",
    "else:\n",
    "    print(\"STATUS: Performance within acceptable ranges\")\n",
    "\n",
    "print(f\"Threat indicator set: {analyzer.threat_indicators['performance_degradation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43724d9b",
   "metadata": {},
   "source": [
    "### üìà **Performance Trend Analysis Results**\n",
    "\n",
    "**This analysis compares recent performance vs. historical baseline:**\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Baseline average**: ~94% (what the model should perform at)\n",
    "- **Recent average**: ~67% (last 6 hours of performance)  \n",
    "- **Performance degradation**: ~28% decline\n",
    "\n",
    "**Threat Detection Status**: ‚úÖ **THREAT DETECTED**\n",
    "\n",
    "**What This Tells Us:**\n",
    "1. **Clear Performance Decline**: The model was performing excellently but has recently degraded significantly\n",
    "2. **Threat Threshold Exceeded**: 28% > 15% threshold triggers threat detection\n",
    "3. **Timeline**: The degradation happened over recent hours, suggesting an active incident\n",
    "\n",
    "**Professional Context**: In real AI security operations, this type of trend analysis helps distinguish between:\n",
    "- Normal performance fluctuations (random variations)\n",
    "- Gradual model drift (slow degradation over time)\n",
    "- **Acute security incidents** (rapid, significant performance loss) ‚Üê **This scenario**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eb20b3",
   "metadata": {},
   "source": [
    "### Performance Trend Analysis Explained\n",
    "\n",
    "The analysis above compares:\n",
    "- **Recent performance**: Average of last 6 hours (during the attack)\n",
    "- **Baseline performance**: Average of previous 6 days (normal operation)\n",
    "- **Degradation threshold**: 10% drop triggers a threat detection\n",
    "\n",
    "**Why this matters**: This is often the first indicator of an AI security incident. Performance drops can indicate:\n",
    "- Data poisoning affecting model predictions\n",
    "- Adversarial attacks targeting specific inputs\n",
    "- Model corruption or unauthorized modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7df082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection simulation\n",
    "def detect_anomalous_patterns(performance_data):\n",
    "    \"\"\"Simulate anomaly detection in AI system metrics\"\"\"\n",
    "    # Extract metrics from performance data\n",
    "    accuracies = [point['accuracy'] for point in performance_data]\n",
    "    response_times = [point['response_time'] for point in performance_data]\n",
    "    throughput = [point['throughput'] for point in performance_data]\n",
    "    \n",
    "    # Simulate anomaly detection (in real scenario, this would use ML algorithms)\n",
    "    accuracy_std = np.std(accuracies)\n",
    "    response_std = np.std(response_times)\n",
    "    \n",
    "    # Count anomalies based on statistical thresholds\n",
    "    accuracy_threshold = np.mean(accuracies) - 2 * accuracy_std\n",
    "    response_threshold = np.mean(response_times) + 2 * response_std\n",
    "    \n",
    "    accuracy_anomalies = sum(1 for acc in accuracies[-24:] if acc < accuracy_threshold)\n",
    "    response_anomalies = sum(1 for rt in response_times[-24:] if rt > response_threshold)\n",
    "    \n",
    "    total_anomalies = accuracy_anomalies + response_anomalies\n",
    "    anomaly_percentage = (total_anomalies / 24) * 100  # Last 24 hours\n",
    "    \n",
    "    # Calculate composite anomaly score\n",
    "    anomaly_score = min(1.0, total_anomalies / 10)  # Normalize to 0-1\n",
    "    \n",
    "    threat_detected = anomaly_score > 0.3  # 30% threshold\n",
    "    \n",
    "    return {\n",
    "        'anomaly_count': total_anomalies,\n",
    "        'anomaly_percentage': anomaly_percentage,\n",
    "        'anomaly_score': anomaly_score,\n",
    "        'accuracy_anomalies': accuracy_anomalies,\n",
    "        'response_anomalies': response_anomalies,\n",
    "        'threat_detected': threat_detected\n",
    "    }\n",
    "\n",
    "print(\"\\nANOMALY PATTERN ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "anomaly_analysis = detect_anomalous_patterns(performance_data)\n",
    "print(f\"Anomalies detected (24h): {anomaly_analysis['anomaly_count']}\")\n",
    "print(f\"Anomaly rate: {anomaly_analysis['anomaly_percentage']:.1f}%\")\n",
    "print(f\"Anomaly score: {anomaly_analysis['anomaly_score']:.3f}\")\n",
    "print(f\"Accuracy anomalies: {anomaly_analysis['accuracy_anomalies']}\")\n",
    "print(f\"Response time anomalies: {anomaly_analysis['response_anomalies']}\")\n",
    "\n",
    "if anomaly_analysis['threat_detected']:\n",
    "    print(\"THREAT DETECTED: Anomalous patterns identified\")\n",
    "    analyzer.threat_indicators['anomaly_detection'] = True\n",
    "else:\n",
    "    print(\"STATUS: No significant anomalies detected\")\n",
    "    analyzer.threat_indicators['anomaly_detection'] = False\n",
    "\n",
    "print(f\"Threat indicator set: {analyzer.threat_indicators['anomaly_detection']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054a62a",
   "metadata": {},
   "source": [
    "### üîç **Anomaly Detection Analysis**\n",
    "\n",
    "**The system analyzed patterns over the last 24 hours and found:**\n",
    "\n",
    "**Anomaly Statistics:**\n",
    "- **Total anomalies**: 3 unusual events detected\n",
    "- **Anomaly rate**: 12.5% (3 out of 24 hours had anomalous behavior)\n",
    "- **Anomaly score**: 0.300 (on a scale of 0-1, where 1 = maximum anomalies)\n",
    "\n",
    "**Breakdown:**\n",
    "- **Accuracy anomalies**: 0 (no unusual accuracy patterns detected)\n",
    "- **Response time anomalies**: 3 (system responding slower than normal)\n",
    "\n",
    "**Threat Assessment**: ‚ö†Ô∏è **Below Threat Threshold** (0.300 < 0.30 threshold)\n",
    "\n",
    "**What This Means:**\n",
    "- The system detected some unusual response time patterns\n",
    "- However, the overall anomaly level is just at the threshold\n",
    "- This suggests potential system stress but not a clear attack pattern\n",
    "- **Combined with performance degradation**, this adds to our concern level\n",
    "\n",
    "**Professional Insight**: Anomaly detection often provides early warning signs. While this alone might not trigger an alert, combined with the severe performance drop, it supports our HIGH severity classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec190254",
   "metadata": {},
   "source": [
    "### Anomaly Pattern Detection Explained\n",
    "\n",
    "This analysis uses **statistical Z-scores** to find unusual patterns:\n",
    "\n",
    "1. **Rolling Statistics**: Calculate 6-hour moving averages and standard deviations\n",
    "2. **Z-Score Calculation**: Measure how far each data point deviates from the rolling mean\n",
    "3. **Outlier Detection**: Values more than 2 standard deviations away are flagged as anomalies\n",
    "4. **Threat Assessment**: More than 3 anomalies in 24 hours indicates an attack\n",
    "\n",
    "**Real-world application**: This helps detect sophisticated attacks that create irregular patterns rather than steady degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data drift detection simulation\n",
    "def simulate_data_drift():\n",
    "    \"\"\"Simulate data drift detection with realistic scores\"\"\"\n",
    "    drift_scores = {\n",
    "        'feature_drift': np.random.uniform(0.3, 0.7),    # Moderate drift\n",
    "        'concept_drift': np.random.uniform(0.1, 0.4),    # Low-moderate drift\n",
    "        'covariate_shift': np.random.uniform(0.4, 0.8)   # Moderate-high drift\n",
    "    }\n",
    "    \n",
    "    max_drift = max(drift_scores.values())\n",
    "    threat_detected = max_drift > 0.5  # 50% drift threshold\n",
    "    \n",
    "    return {\n",
    "        'drift_scores': drift_scores,\n",
    "        'max_drift': max_drift,\n",
    "        'threat_detected': threat_detected,\n",
    "        'drift_magnitude': max_drift\n",
    "    }\n",
    "\n",
    "# Adversarial attack probability assessment\n",
    "def simulate_adversarial_detection():\n",
    "    \"\"\"Simulate adversarial attack detection\"\"\"\n",
    "    # Check for adversarial patterns\n",
    "    adversarial_indicators = {\n",
    "        'input_perturbations': np.random.uniform(0.1, 0.8),\n",
    "        'gradient_anomalies': np.random.uniform(0.2, 0.9),\n",
    "        'confidence_drops': np.random.uniform(0.3, 0.7)\n",
    "    }\n",
    "    \n",
    "    # Calculate overall adversarial probability\n",
    "    adversarial_score = np.mean(list(adversarial_indicators.values()))\n",
    "    adversarial_probability = adversarial_score * 100\n",
    "    threat_detected = adversarial_probability > 60  # 60% threshold\n",
    "    \n",
    "    return {\n",
    "        'indicators': adversarial_indicators,\n",
    "        'adversarial_score': adversarial_score,\n",
    "        'adversarial_probability': adversarial_probability,\n",
    "        'threat_detected': threat_detected\n",
    "    }\n",
    "\n",
    "print(\"\\nDATA DRIFT ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "drift_analysis = simulate_data_drift()\n",
    "print(f\"Feature drift: {drift_analysis['drift_scores']['feature_drift']:.3f}\")\n",
    "print(f\"Concept drift: {drift_analysis['drift_scores']['concept_drift']:.3f}\")\n",
    "print(f\"Covariate shift: {drift_analysis['drift_scores']['covariate_shift']:.3f}\")\n",
    "print(f\"Maximum drift detected: {drift_analysis['max_drift']:.3f}\")\n",
    "\n",
    "if drift_analysis['threat_detected']:\n",
    "    print(\"WARNING: Significant data drift detected\")\n",
    "else:\n",
    "    print(\"INFO: Data drift within acceptable ranges\")\n",
    "\n",
    "print(\"\\nADVERSARIAL ATTACK DETECTION\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "adversarial_analysis = simulate_adversarial_detection()\n",
    "print(f\"Input perturbations: {adversarial_analysis['indicators']['input_perturbations']:.3f}\")\n",
    "print(f\"Gradient anomalies: {adversarial_analysis['indicators']['gradient_anomalies']:.3f}\")\n",
    "print(f\"Confidence drops: {adversarial_analysis['indicators']['confidence_drops']:.3f}\")\n",
    "print(f\"Adversarial probability: {adversarial_analysis['adversarial_probability']:.1f}%\")\n",
    "\n",
    "if adversarial_analysis['threat_detected']:\n",
    "    print(\"ALERT: High probability adversarial attack detected\")\n",
    "else:\n",
    "    print(\"INFO: No adversarial attack patterns detected\")\n",
    "\n",
    "# Store all analysis results in the analyzer\n",
    "analyzer.drift_analysis = drift_analysis\n",
    "analyzer.adversarial_analysis = adversarial_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c646e",
   "metadata": {},
   "source": [
    "### üìä **Data Drift & Adversarial Attack Analysis**\n",
    "\n",
    "**This analysis checked for two critical security threats:**\n",
    "\n",
    "## **Data Drift Analysis** üìà\n",
    "- **Feature drift**: 0.351 (data characteristics changing)\n",
    "- **Concept drift**: 0.219 (relationship between inputs/outputs changing)  \n",
    "- **Covariate shift**: 0.719 ‚ö†Ô∏è (input distribution changing significantly)\n",
    "- **Maximum drift**: 0.719 ‚Üí **WARNING: Significant data drift detected**\n",
    "\n",
    "## **Adversarial Attack Detection** üõ°Ô∏è\n",
    "- **Input perturbations**: 0.205 (small modifications to inputs)\n",
    "- **Gradient anomalies**: 0.360 (unusual model behavior patterns)\n",
    "- **Confidence drops**: 0.589 (model becoming less certain)\n",
    "- **Adversarial probability**: 38.5% ‚Üí **Below 60% threshold**\n",
    "\n",
    "**Key Insights:**\n",
    "1. **Data Drift Confirmed**: The high covariate shift (0.719) indicates the incoming data distribution has changed significantly\n",
    "2. **Possible Attack Vector**: This could indicate data poisoning or distribution shift attacks\n",
    "3. **Adversarial Evidence**: While not definitive (38.5% < 60%), the confidence drops are concerning\n",
    "\n",
    "**Security Implication**: Data drift can be natural (changing user behavior) or malicious (data poisoning attacks). Combined with performance degradation, this suggests a potential security incident rather than natural drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial input detection simulation\n",
    "def simulate_adversarial_detection():\n",
    "    \"\"\"Simulate adversarial input detection results\"\"\"\n",
    "    total_requests = 10000\n",
    "    adversarial_detected = np.random.randint(80, 120)  # 0.8-1.2% adversarial inputs\n",
    "    \n",
    "    adversarial_rate = adversarial_detected / total_requests\n",
    "    threat_detected = adversarial_rate > 0.01  # 1% threshold\n",
    "    \n",
    "    if threat_detected:\n",
    "        analyzer.threat_indicators['adversarial_inputs'] = True\n",
    "        \n",
    "    return {\n",
    "        'total_requests': total_requests,\n",
    "        'adversarial_detected': adversarial_detected,\n",
    "        'adversarial_rate': adversarial_rate * 100,\n",
    "        'threat_detected': threat_detected\n",
    "    }\n",
    "\n",
    "print(\"\\nüîç ADVERSARIAL INPUT ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "adv_analysis = simulate_adversarial_detection()\n",
    "print(f\"Total requests analyzed: {adv_analysis['total_requests']:,}\")\n",
    "print(f\"Adversarial inputs detected: {adv_analysis['adversarial_detected']}\")\n",
    "print(f\"Adversarial rate: {adv_analysis['adversarial_rate']:.2f}%\")\n",
    "print(f\"Threat Status: {'üö® DETECTED' if adv_analysis['threat_detected'] else '‚úÖ CLEAR'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall threat assessment\n",
    "threats_detected = sum(analyzer.threat_indicators.values())\n",
    "\n",
    "print(\"\\nOVERALL THREAT ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Combine all threat indicators\n",
    "threat_indicators = {\n",
    "    'performance_drop': performance_analysis['performance_drop'],\n",
    "    'anomaly_score': anomaly_analysis['anomaly_score'],\n",
    "    'drift_magnitude': drift_analysis['drift_magnitude'],\n",
    "    'adversarial_prob': adversarial_analysis['adversarial_probability'],\n",
    "    'primary_threat': 'MULTIPLE_INDICATORS'\n",
    "}\n",
    "\n",
    "print(f\"Threats detected: {threats_detected}/4 categories\")\n",
    "print(f\"Performance degradation: {threat_indicators['performance_drop']:.1f}%\")\n",
    "print(f\"Anomaly detection score: {threat_indicators['anomaly_score']:.3f}\")\n",
    "print(f\"Data drift magnitude: {threat_indicators['drift_magnitude']:.3f}\")\n",
    "print(f\"Adversarial attack probability: {threat_indicators['adversarial_prob']:.1f}%\")\n",
    "\n",
    "# Classify overall incident severity\n",
    "if threats_detected >= 3:\n",
    "    incident_severity = \"CRITICAL\"\n",
    "    incident_classification = \"CRITICAL_MULTI_VECTOR\"\n",
    "    print(\"\\nSEVERITY: CRITICAL - Multiple threat vectors detected\")\n",
    "elif threats_detected >= 2:\n",
    "    incident_severity = \"HIGH\"  \n",
    "    incident_classification = \"HIGH_DUAL_THREAT\"\n",
    "    print(\"\\nSEVERITY: HIGH - Dual threat scenario\")\n",
    "elif threats_detected >= 1:\n",
    "    incident_severity = \"MEDIUM\"\n",
    "    incident_classification = \"MEDIUM_SINGLE_THREAT\"\n",
    "    print(\"\\nSEVERITY: MEDIUM - Single threat detected\")\n",
    "else:\n",
    "    incident_severity = \"LOW\"\n",
    "    incident_classification = \"LOW_MONITORING\"\n",
    "    print(\"\\nSEVERITY: LOW - No immediate threats\")\n",
    "\n",
    "print(f\"Classification: {incident_classification}\")\n",
    "print(f\"Response protocol: {'IMMEDIATE' if threats_detected >= 2 else 'STANDARD'}\")\n",
    "\n",
    "# Alert status\n",
    "if threats_detected >= 2:\n",
    "    print(\"\\nALERT: Immediate containment procedures required\")\n",
    "else:\n",
    "    print(\"\\nSTATUS: Continue monitoring, standard procedures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d3c3e",
   "metadata": {},
   "source": [
    "### üéØ **Overall Threat Assessment Summary**\n",
    "\n",
    "**The system has analyzed all indicators and made a final classification:**\n",
    "\n",
    "**Threat Detection Results:**\n",
    "- **Threats detected**: 1 out of 4 threat categories triggered\n",
    "- **Primary threat**: Data drift (significant covariate shift detected)\n",
    "\n",
    "**Individual Threat Indicators:**\n",
    "- **Performance degradation**: 29.1% (HIGH concern)\n",
    "- **Anomaly detection**: 0.300 (moderate concern)  \n",
    "- **Data drift**: 0.719 (HIGH concern - primary threat)\n",
    "- **Adversarial probability**: 38.5% (moderate concern)\n",
    "\n",
    "**Final Classification:**\n",
    "- **Severity**: MEDIUM (only 1 category triggered, but with high individual scores)\n",
    "- **Classification**: MEDIUM_SINGLE_THREAT\n",
    "- **Response protocol**: STANDARD monitoring procedures\n",
    "\n",
    "**Why MEDIUM Instead of HIGH?**\n",
    "While individual metrics are concerning (29.1% performance drop), only 1 out of 4 threat categories definitively triggered. The system uses conservative thresholds to avoid false alarms.\n",
    "\n",
    "**Key Takeaway**: This demonstrates how AI security systems balance sensitivity with specificity. Real-world systems must minimize false positives while catching genuine threats. The 29.1% performance drop with significant data drift still warrants investigation, even at MEDIUM severity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40e865",
   "metadata": {},
   "source": [
    "## Phase 3: Incident Response Execution (10 minutes)\n",
    "\n",
    "Now let's execute our incident response plan based on the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef724614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Incident Response Executor (No emojis - safe for parser)\n",
    "class IncidentResponseExecutor:\n",
    "    def __init__(self):\n",
    "        self.response_log = []\n",
    "        \n",
    "    def log_action(self, action, status, details=\"\"):\n",
    "        \"\"\"Log response actions with timestamp\"\"\"\n",
    "        self.response_log.append({\n",
    "            'timestamp': datetime.now().strftime(\"%H:%M:%S\"),\n",
    "            'action': action,\n",
    "            'status': status,\n",
    "            'details': details\n",
    "        })\n",
    "        print(f\"[{self.response_log[-1]['timestamp']}] {action}: {status}\")\n",
    "        if details:\n",
    "            print(f\"    Details: {details}\")\n",
    "        \n",
    "    def execute_immediate_containment(self, incident_type):\n",
    "        \"\"\"Execute immediate containment actions based on incident type\"\"\"\n",
    "        print(\"ALERT: EXECUTING IMMEDIATE CONTAINMENT\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Standard containment actions\n",
    "        actions = [\n",
    "            (\"Isolate affected model\", \"SUCCESS\", \"Model traffic redirected to backup\"),\n",
    "            (\"Preserve evidence\", \"SUCCESS\", \"Model state and logs captured\"),\n",
    "            (\"Alert security team\", \"SUCCESS\", \"Team notified via automated alert\"),\n",
    "            (\"Assess blast radius\", \"SUCCESS\", f\"Impact: {incident_type} affecting 100K users\")\n",
    "        ]\n",
    "        \n",
    "        for action, status, details in actions:\n",
    "            self.log_action(action, status, details)\n",
    "            \n",
    "        return len([a for a in actions if a[1] == \"SUCCESS\"])\n",
    "\n",
    "# Initialize and execute response\n",
    "executor = IncidentResponseExecutor()\n",
    "successful_actions = executor.execute_immediate_containment(incident_classification)\n",
    "\n",
    "print(f\"\\nImmediate containment: {successful_actions}/4 actions successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f58241",
   "metadata": {},
   "source": [
    "### ‚ö° **Incident Response Execution Results**\n",
    "\n",
    "**The automated response system successfully executed all containment procedures!**\n",
    "\n",
    "**Response Actions Completed (4/4 SUCCESS):**\n",
    "\n",
    "1. **üîí Isolate affected model: SUCCESS**\n",
    "   - **What happened**: Traffic was redirected from the compromised model to a backup system\n",
    "   - **Why important**: Prevents further damage and protects users from poor predictions\n",
    "\n",
    "2. **üìã Preserve evidence: SUCCESS**  \n",
    "   - **What happened**: Model state and system logs were captured for forensic analysis\n",
    "   - **Why important**: Essential for understanding the attack and legal compliance\n",
    "\n",
    "3. **üö® Alert security team: SUCCESS**\n",
    "   - **What happened**: Automated notifications sent to security personnel\n",
    "   - **Why important**: Human experts can take over complex response decisions\n",
    "\n",
    "4. **üìä Assess blast radius: SUCCESS**\n",
    "   - **What happened**: System determined impact scope (100K users affected)\n",
    "   - **Why important**: Helps prioritize resources and communication strategies\n",
    "\n",
    "**Professional Context**: This demonstrates the **\"Golden Hour\"** principle in incident response - taking immediate action within the first hour of detection. Automated responses like these can contain damage while human responders are mobilizing.\n",
    "\n",
    "**Result**: Perfect execution means the threat is contained and ready for detailed investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080d1ab",
   "metadata": {},
   "source": [
    "### Incident Response Execution Explained\n",
    "\n",
    "The containment phase focuses on **immediate damage control**:\n",
    "\n",
    "1. **Model Isolation**: Redirect traffic to backup/fallback systems to prevent further damage\n",
    "2. **Evidence Preservation**: Capture current model state and system logs before any changes\n",
    "3. **Team Notification**: Alert the incident response team through automated channels\n",
    "4. **Impact Assessment**: Determine scope and severity of the incident\n",
    "\n",
    "**Key Principle**: Act fast to stop ongoing damage while preserving evidence for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess containment effectiveness and plan recovery\n",
    "def assess_containment_effectiveness():\n",
    "    \"\"\"Evaluate how effective our containment actions were\"\"\"\n",
    "    \n",
    "    # Simulate containment assessment based on incident severity and actions taken\n",
    "    base_effectiveness = 60  # Base containment effectiveness\n",
    "    \n",
    "    # Bonus for successful actions\n",
    "    action_bonus = (successful_actions / 4) * 30  # Up to 30% bonus for all actions successful\n",
    "    \n",
    "    # Penalty for high severity incidents\n",
    "    severity_penalty = 0\n",
    "    if incident_severity == \"CRITICAL\":\n",
    "        severity_penalty = 15\n",
    "    elif incident_severity == \"HIGH\":\n",
    "        severity_penalty = 10\n",
    "        \n",
    "    total_effectiveness = min(95, base_effectiveness + action_bonus - severity_penalty)\n",
    "    \n",
    "    # Simulate new model accuracy after containment\n",
    "    if total_effectiveness > 80:\n",
    "        new_accuracy = np.random.uniform(0.75, 0.85)  # Significant improvement\n",
    "        status = \"EFFECTIVE\"\n",
    "    elif total_effectiveness > 60:\n",
    "        new_accuracy = np.random.uniform(0.70, 0.80)  # Moderate improvement\n",
    "        status = \"PARTIALLY_EFFECTIVE\"\n",
    "    else:\n",
    "        new_accuracy = np.random.uniform(0.65, 0.75)  # Limited improvement\n",
    "        status = \"LIMITED_EFFECTIVENESS\"\n",
    "    \n",
    "    return {\n",
    "        'effectiveness_percentage': total_effectiveness,\n",
    "        'new_accuracy': new_accuracy,\n",
    "        'containment_status': status\n",
    "    }\n",
    "\n",
    "print(\"\\nCONTAINMENT EFFECTIVENESS ASSESSMENT\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "containment_assessment = assess_containment_effectiveness()\n",
    "print(f\"Containment effectiveness: {containment_assessment['effectiveness_percentage']:.1f}%\")\n",
    "print(f\"New model accuracy: {containment_assessment['new_accuracy']:.3f}\")\n",
    "print(f\"Status: {containment_assessment['containment_status']}\")\n",
    "\n",
    "if containment_assessment['containment_status'] == 'EFFECTIVE':\n",
    "    print(\"SUCCESS: Containment successful - proceeding with recovery\")\n",
    "else:\n",
    "    print(\"WARNING: Containment partially effective - enhanced measures needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3dc4d",
   "metadata": {},
   "source": [
    "### ‚úÖ **Containment Effectiveness Assessment**\n",
    "\n",
    "**Excellent news! Our containment procedures were highly effective:**\n",
    "\n",
    "**Assessment Results:**\n",
    "- **Containment effectiveness**: 90.0% (Excellent performance!)\n",
    "- **New model accuracy**: 0.822 (82.2% - significant improvement from ~70%)\n",
    "- **Status**: EFFECTIVE (containment successful)\n",
    "\n",
    "**How This Was Calculated:**\n",
    "- **Base effectiveness**: 60% (standard containment baseline)\n",
    "- **Action bonus**: +30% (all 4 response actions successful)\n",
    "- **Severity penalty**: -10% (MEDIUM severity penalty applied)\n",
    "- **Total**: 60% + 30% - 10% = 80%+ = EFFECTIVE status\n",
    "\n",
    "**What This Means:**\n",
    "1. **Immediate Threat Neutralized**: Model performance improved from ~70% to 82%\n",
    "2. **Recovery Successful**: The backup systems are functioning well\n",
    "3. **Damage Limited**: Quick response prevented further degradation\n",
    "\n",
    "**Professional Context**: \n",
    "- **80%+ effectiveness** = Incident contained, proceed with recovery\n",
    "- **60-80% effectiveness** = Partially contained, additional measures needed  \n",
    "- **<60% effectiveness** = Limited success, escalate to emergency protocols\n",
    "\n",
    "**Next Steps**: With EFFECTIVE containment, we can now focus on full system recovery and post-incident analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428546ac",
   "metadata": {},
   "source": [
    "## Phase 4: Stakeholder Communication (4 minutes)\n",
    "\n",
    "Let's generate appropriate communications for different stakeholder groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "class StakeholderCommunicationManager:\n",
    "    \"\"\"Manages communications with different stakeholder groups during incident response\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.communications_log = []\n",
    "        self.stakeholder_groups = {\n",
    "            'technical_team': ['DevOps Engineer', 'ML Engineer', 'Security Analyst'],\n",
    "            'management': ['CISO', 'Engineering Director', 'Product Manager'],\n",
    "            'external': ['Customer Support', 'Public Relations', 'Legal Team']\n",
    "        }\n",
    "    \n",
    "    def send_initial_alert(self, incident_severity, threat_type):\n",
    "        \"\"\"Send initial incident notification to all stakeholders\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Technical team gets detailed info\n",
    "        tech_message = f\"INCIDENT ALERT: {threat_type} detected with {incident_severity} severity. Technical response initiated.\"\n",
    "        self.log_communication('technical_team', tech_message, timestamp)\n",
    "        \n",
    "        # Management gets summary\n",
    "        mgmt_message = f\"Incident escalation: {incident_severity} severity security event in AI system. Response team activated.\"\n",
    "        self.log_communication('management', mgmt_message, timestamp)\n",
    "        \n",
    "        # External teams get basic notification\n",
    "        ext_message = f\"Security incident notification: AI system monitoring in progress. Standby for updates.\"\n",
    "        self.log_communication('external', ext_message, timestamp)\n",
    "        \n",
    "        return f\"Alert notifications sent to all stakeholder groups at {timestamp}\"\n",
    "    \n",
    "    def provide_status_update(self, containment_status, actions_taken):\n",
    "        \"\"\"Provide ongoing status updates during incident response\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Calculate response progress\n",
    "        progress = (actions_taken / 4) * 100  # 4 total response actions\n",
    "        \n",
    "        status_msg = f\"UPDATE {timestamp}: Containment {containment_status}, {progress:.0f}% response actions completed\"\n",
    "        \n",
    "        # All groups get status updates but with different detail levels\n",
    "        for group in self.stakeholder_groups:\n",
    "            if group == 'technical_team':\n",
    "                detailed_msg = f\"{status_msg}. Technical measures in progress.\"\n",
    "            elif group == 'management':\n",
    "                detailed_msg = f\"{status_msg}. Business impact being assessed.\"\n",
    "            else:\n",
    "                detailed_msg = f\"{status_msg}. Customer-facing services monitored.\"\n",
    "            \n",
    "            self.log_communication(group, detailed_msg, timestamp)\n",
    "        \n",
    "        return status_msg\n",
    "    \n",
    "    def send_resolution_notice(self, effectiveness_score, final_status):\n",
    "        \"\"\"Send incident resolution communications\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        if effectiveness_score > 80:\n",
    "            resolution_status = \"RESOLVED\"\n",
    "            confidence = \"High confidence in resolution\"\n",
    "        elif effectiveness_score > 60:\n",
    "            resolution_status = \"CONTAINED\"\n",
    "            confidence = \"Moderate confidence, monitoring continues\"\n",
    "        else:\n",
    "            resolution_status = \"STABILIZED\"\n",
    "            confidence = \"Limited effectiveness, enhanced monitoring required\"\n",
    "        \n",
    "        final_msg = f\"FINAL UPDATE {timestamp}: Incident {resolution_status}. {confidence}.\"\n",
    "        \n",
    "        # Send to all groups\n",
    "        for group in self.stakeholder_groups:\n",
    "            self.log_communication(group, final_msg, timestamp)\n",
    "        \n",
    "        return final_msg\n",
    "    \n",
    "    def log_communication(self, group, message, timestamp):\n",
    "        \"\"\"Log all communications for audit trail\"\"\"\n",
    "        self.communications_log.append({\n",
    "            'timestamp': timestamp,\n",
    "            'stakeholder_group': group,\n",
    "            'message': message\n",
    "        })\n",
    "    \n",
    "    def get_communications_summary(self):\n",
    "        \"\"\"Return summary of all communications sent\"\"\"\n",
    "        summary = {\n",
    "            'total_messages': len(self.communications_log),\n",
    "            'messages_by_group': {},\n",
    "            'timeline': []\n",
    "        }\n",
    "        \n",
    "        for group in self.stakeholder_groups:\n",
    "            summary['messages_by_group'][group] = len([\n",
    "                msg for msg in self.communications_log \n",
    "                if msg['stakeholder_group'] == group\n",
    "            ])\n",
    "        \n",
    "        # Get timeline of key communications\n",
    "        summary['timeline'] = [\n",
    "            f\"{msg['timestamp']}: {msg['stakeholder_group']} - {msg['message'][:50]}...\"\n",
    "            for msg in self.communications_log[-6:]  # Last 6 messages\n",
    "        ]\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize communication manager\n",
    "comm_manager = StakeholderCommunicationManager()\n",
    "\n",
    "print(\"STAKEHOLDER COMMUNICATIONS\")\n",
    "print(\"=\" * 29)\n",
    "print(\"Initializing communication channels with stakeholder groups...\")\n",
    "print(\"Technical Team:\", comm_manager.stakeholder_groups['technical_team'])\n",
    "print(\"Management:\", comm_manager.stakeholder_groups['management'])\n",
    "print(\"External Teams:\", comm_manager.stakeholder_groups['external'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755a099",
   "metadata": {},
   "source": [
    "### üì¢ **Stakeholder Communication System Setup**\n",
    "\n",
    "**This output shows our communication system is ready to notify all relevant parties:**\n",
    "\n",
    "**Stakeholder Groups Configured:**\n",
    "\n",
    "1. **Technical Team** (immediate technical response):\n",
    "   - DevOps Engineer (system operations)\n",
    "   - ML Engineer (model expertise)  \n",
    "   - Security Analyst (threat analysis)\n",
    "\n",
    "2. **Management** (business decision making):\n",
    "   - CISO (security leadership)\n",
    "   - Engineering Director (resource allocation)\n",
    "   - Product Manager (user impact assessment)\n",
    "\n",
    "3. **External Teams** (customer and public impact):\n",
    "   - Customer Support (user communications)\n",
    "   - Public Relations (media management)\n",
    "   - Legal Team (compliance and liability)\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Different groups need different information** (technical details vs. business impact)\n",
    "- **Timing is critical** (technical teams first, then management, then external)\n",
    "- **Audit trail required** (all communications logged for compliance)\n",
    "\n",
    "**Professional Context**: In real incidents, poor communication can be as damaging as the technical problem itself. This system ensures the right people get the right information at the right time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send initial incident alert to all stakeholders\n",
    "print(\"\\nINITIAL INCIDENT COMMUNICATION\")\n",
    "print(\"=\" * 32)\n",
    "\n",
    "initial_alert = comm_manager.send_initial_alert(incident_severity, threat_indicators['primary_threat'])\n",
    "print(initial_alert)\n",
    "print()\n",
    "\n",
    "# Show what each stakeholder group received\n",
    "print(\"Messages sent to stakeholder groups:\")\n",
    "for group_name, members in comm_manager.stakeholder_groups.items():\n",
    "    latest_msg = [msg for msg in comm_manager.communications_log if msg['stakeholder_group'] == group_name][-1]\n",
    "    print(f\"\\n{group_name.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  Recipients: {', '.join(members)}\")\n",
    "    print(f\"  Message: {latest_msg['message']}\")\n",
    "    print(f\"  Time: {latest_msg['timestamp']}\")\n",
    "\n",
    "print(f\"\\nTotal initial notifications sent: {len(comm_manager.communications_log)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8facd225",
   "metadata": {},
   "source": [
    "### üì® **Initial Incident Communications Analysis**\n",
    "\n",
    "**All stakeholder groups have been successfully notified! Here's what happened:**\n",
    "\n",
    "**Communication Results:**\n",
    "- **Total notifications sent**: 3 (one to each stakeholder group)\n",
    "- **Notification time**: All sent simultaneously for rapid response\n",
    "- **Message customization**: Each group received tailored information\n",
    "\n",
    "**Message Content Analysis:**\n",
    "\n",
    "1. **Technical Team Message**: \n",
    "   - **Focus**: Technical details (\"MULTIPLE_INDICATORS detected\")\n",
    "   - **Action**: \"Technical response initiated\"\n",
    "   - **Purpose**: Enables immediate technical investigation\n",
    "\n",
    "2. **Management Message**:\n",
    "   - **Focus**: Business impact (\"MEDIUM severity security event\")  \n",
    "   - **Action**: \"Response team activated\"\n",
    "   - **Purpose**: Informs business decision makers\n",
    "\n",
    "3. **External Teams Message**:\n",
    "   - **Focus**: Monitoring status (\"AI system monitoring in progress\")\n",
    "   - **Action**: \"Standby for updates\"\n",
    "   - **Purpose**: Prepares customer-facing teams without causing panic\n",
    "\n",
    "**Professional Best Practices Demonstrated:**\n",
    "- **Parallel notification** (everyone informed simultaneously)\n",
    "- **Tailored messaging** (appropriate detail level for each audience)\n",
    "- **Clear action items** (each group knows their next steps)\n",
    "- **Audit trail** (all communications logged with timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide ongoing status updates during response\n",
    "print(\"\\nSTATUS UPDATE COMMUNICATIONS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "status_update = comm_manager.provide_status_update(\n",
    "    containment_assessment['containment_status'], \n",
    "    successful_actions\n",
    ")\n",
    "print(status_update)\n",
    "\n",
    "# Send final resolution notice\n",
    "print(\"\\nFINAL RESOLUTION COMMUNICATION\") \n",
    "print(\"=\" * 32)\n",
    "\n",
    "resolution_notice = comm_manager.send_resolution_notice(\n",
    "    containment_assessment['effectiveness_percentage'],\n",
    "    containment_assessment['containment_status']\n",
    ")\n",
    "print(resolution_notice)\n",
    "\n",
    "# Get comprehensive communications summary\n",
    "print(\"\\nCOMMUNICATIONS AUDIT TRAIL\")\n",
    "print(\"=\" * 28)\n",
    "\n",
    "comm_summary = comm_manager.get_communications_summary()\n",
    "print(f\"Total messages sent: {comm_summary['total_messages']}\")\n",
    "print(\"\\nMessages by stakeholder group:\")\n",
    "for group, count in comm_summary['messages_by_group'].items():\n",
    "    print(f\"  {group.replace('_', ' ').title()}: {count} messages\")\n",
    "\n",
    "print(\"\\nCommunication timeline (recent):\")\n",
    "for timeline_entry in comm_summary['timeline']:\n",
    "    print(f\"  {timeline_entry}\")\n",
    "\n",
    "print(\"\\nSTATUS: All stakeholder communications completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da5cbe",
   "metadata": {},
   "source": [
    "### üìã **Communications Lifecycle Complete**\n",
    "\n",
    "**This output shows the complete communications timeline from incident to resolution:**\n",
    "\n",
    "## **Status Update Communication**\n",
    "- **Purpose**: Keep stakeholders informed during active response\n",
    "- **Content**: \"Containment EFFECTIVE, 100% response actions completed\"\n",
    "- **Timing**: Sent after containment assessment confirmed success\n",
    "\n",
    "## **Final Resolution Communication**  \n",
    "- **Purpose**: Officially close the incident communication loop\n",
    "- **Content**: \"Incident RESOLVED. High confidence in resolution.\"\n",
    "- **Impact**: All stakeholders know the incident is resolved\n",
    "\n",
    "## **Communications Audit Trail**\n",
    "**Total Impact:**\n",
    "- **9 messages sent** across the entire incident lifecycle\n",
    "- **3 stakeholder groups** consistently updated\n",
    "- **3 messages per group** (initial alert + status update + resolution)\n",
    "\n",
    "**Timeline Analysis:**\n",
    "- **11:49:50**: Initial incident alerts sent to all groups\n",
    "- **11:49:54**: Status updates confirming effective containment  \n",
    "- **11:49:54**: Final resolution notices declaring incident resolved\n",
    "\n",
    "**Professional Value:**\n",
    "1. **Complete Documentation**: Every communication logged for compliance\n",
    "2. **Consistent Messaging**: All groups received updates at same time\n",
    "3. **Clear Resolution**: No ambiguity about incident status\n",
    "4. **Audit Ready**: Complete timeline available for post-incident review\n",
    "\n",
    "**Best Practice**: The 4-minute resolution time demonstrates the power of automated response systems in containing AI security incidents rapidly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0f9b1",
   "metadata": {},
   "source": [
    "### Stakeholder Communication Strategy\n",
    "\n",
    "Different audiences need different information:\n",
    "\n",
    "**Technical Teams**: \n",
    "- Detailed technical metrics and analysis results\n",
    "- Specific actions taken and next steps\n",
    "- Direct contact information for coordination\n",
    "\n",
    "**Executive Leadership**:\n",
    "- Business impact and financial implications  \n",
    "- High-level status and timeline\n",
    "- Strategic recommendations and resource needs\n",
    "\n",
    "**Key Principle**: Tailor the message complexity and focus to the audience's needs and decision-making requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ad100",
   "metadata": {},
   "source": [
    "## Phase 5: Incident Documentation and Lessons Learned (3 minutes)\n",
    "\n",
    "Finally, let's complete our incident documentation and extract lessons learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncidentDocumentationSystem:\n",
    "    \"\"\"Comprehensive incident documentation and reporting system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.incident_report = {}\n",
    "        self.timeline = []\n",
    "        self.lessons_learned = []\n",
    "        \n",
    "    def create_incident_report(self, incident_data, threat_data, response_data, containment_data, comm_data):\n",
    "        \"\"\"Generate comprehensive incident documentation\"\"\"\n",
    "        \n",
    "        self.incident_report = {\n",
    "            'incident_id': f\"INC-{datetime.now().strftime('%Y%m%d%H%M%S')}\",\n",
    "            'detection_time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'severity': incident_data['severity'],\n",
    "            'threat_type': threat_data['primary_threat'],\n",
    "            'initial_indicators': {\n",
    "                'performance_degradation': f\"{threat_data['performance_drop']:.1f}%\",\n",
    "                'anomaly_score': f\"{threat_data['anomaly_score']:.3f}\",\n",
    "                'drift_magnitude': f\"{threat_data['drift_magnitude']:.3f}\",\n",
    "                'adversarial_probability': f\"{threat_data['adversarial_prob']:.1f}%\"\n",
    "            },\n",
    "            'response_actions': {\n",
    "                'isolation_performed': response_data.get('isolation_performed', False),\n",
    "                'monitoring_enhanced': response_data.get('monitoring_enhanced', False),\n",
    "                'access_restricted': response_data.get('access_restricted', False),\n",
    "                'backup_activated': response_data.get('backup_activated', False),\n",
    "                'total_successful': response_data.get('successful_actions', 0)\n",
    "            },\n",
    "            'containment_effectiveness': f\"{containment_data['effectiveness_percentage']:.1f}%\",\n",
    "            'recovery_status': containment_data['containment_status'],\n",
    "            'communications_sent': comm_data['total_messages'],\n",
    "            'stakeholder_groups_notified': len(comm_data['messages_by_group'])\n",
    "        }\n",
    "        \n",
    "        return self.incident_report\n",
    "    \n",
    "    def add_timeline_entry(self, timestamp, event, details):\n",
    "        \"\"\"Add event to incident timeline\"\"\"\n",
    "        self.timeline.append({\n",
    "            'timestamp': timestamp,\n",
    "            'event': event,\n",
    "            'details': details\n",
    "        })\n",
    "    \n",
    "    def document_lessons_learned(self, effectiveness_score):\n",
    "        \"\"\"Generate lessons learned based on incident response\"\"\"\n",
    "        \n",
    "        if effectiveness_score > 80:\n",
    "            self.lessons_learned.extend([\n",
    "                \"Response procedures performed effectively\",\n",
    "                \"Detection systems functioned as expected\", \n",
    "                \"Communication protocols successful\",\n",
    "                \"Recovery time met acceptable thresholds\"\n",
    "            ])\n",
    "        elif effectiveness_score > 60:\n",
    "            self.lessons_learned.extend([\n",
    "                \"Response partially effective - review procedures\",\n",
    "                \"Some detection delays observed\",\n",
    "                \"Communication timing could be improved\",\n",
    "                \"Recovery procedures need optimization\"\n",
    "            ])\n",
    "        else:\n",
    "            self.lessons_learned.extend([\n",
    "                \"Response procedures require significant improvement\",\n",
    "                \"Detection systems need enhancement\",\n",
    "                \"Communication protocols must be revised\", \n",
    "                \"Recovery procedures inadequate\"\n",
    "            ])\n",
    "    \n",
    "    def generate_executive_summary(self):\n",
    "        \"\"\"Create executive summary for management\"\"\"\n",
    "        \n",
    "        report = self.incident_report\n",
    "        summary = f\"\"\"\n",
    "EXECUTIVE INCIDENT SUMMARY\n",
    "Report ID: {report['incident_id']}\n",
    "Detection Time: {report['detection_time']}\n",
    "\n",
    "INCIDENT OVERVIEW:\n",
    "- Severity Level: {report['severity']}\n",
    "- Threat Type: {report['threat_type']}\n",
    "- Containment Effectiveness: {report['containment_effectiveness']}\n",
    "- Final Status: {report['recovery_status']}\n",
    "\n",
    "KEY METRICS:\n",
    "- Response Actions Completed: {report['response_actions']['total_successful']}/4\n",
    "- Stakeholder Groups Notified: {report['stakeholder_groups_notified']}\n",
    "- Total Communications Sent: {report['communications_sent']}\n",
    "\n",
    "TECHNICAL INDICATORS:\n",
    "- Performance Impact: {report['initial_indicators']['performance_degradation']}\n",
    "- Anomaly Detection Score: {report['initial_indicators']['anomaly_score']}\n",
    "- Model Drift Level: {report['initial_indicators']['drift_magnitude']}\n",
    "- Adversarial Attack Probability: {report['initial_indicators']['adversarial_probability']}\n",
    "\n",
    "STATUS: Incident response completed with {report['containment_effectiveness']} effectiveness\n",
    "        \"\"\"\n",
    "        \n",
    "        return summary.strip()\n",
    "\n",
    "# Create documentation system and generate comprehensive report\n",
    "print(\"INCIDENT DOCUMENTATION SYSTEM\")\n",
    "print(\"=\" * 31)\n",
    "\n",
    "doc_system = IncidentDocumentationSystem()\n",
    "\n",
    "# Create comprehensive incident report\n",
    "incident_report = doc_system.create_incident_report(\n",
    "    incident_data={'severity': incident_severity},\n",
    "    threat_data=threat_indicators,\n",
    "    response_data={'successful_actions': successful_actions},  # Use the variable we have\n",
    "    containment_data=containment_assessment,\n",
    "    comm_data=comm_summary\n",
    ")\n",
    "\n",
    "print(\"Incident report generated successfully\")\n",
    "print(f\"Report ID: {incident_report['incident_id']}\")\n",
    "print(f\"Severity: {incident_report['severity']}\")\n",
    "print(f\"Response effectiveness: {incident_report['containment_effectiveness']}\")\n",
    "\n",
    "# Add timeline entries\n",
    "doc_system.add_timeline_entry(\n",
    "    datetime.now().strftime(\"%H:%M:%S\"),\n",
    "    \"Incident Detection\",\n",
    "    f\"AI system anomaly detected with {incident_severity} severity\"\n",
    ")\n",
    "\n",
    "doc_system.add_timeline_entry(\n",
    "    datetime.now().strftime(\"%H:%M:%S\"), \n",
    "    \"Response Initiated\",\n",
    "    f\"Automated response procedures activated, {successful_actions}/4 actions completed\"\n",
    ")\n",
    "\n",
    "doc_system.add_timeline_entry(\n",
    "    datetime.now().strftime(\"%H:%M:%S\"),\n",
    "    \"Incident Resolved\", \n",
    "    f\"Containment achieved with {containment_assessment['effectiveness_percentage']:.1f}% effectiveness\"\n",
    ")\n",
    "\n",
    "# Document lessons learned\n",
    "doc_system.document_lessons_learned(containment_assessment['effectiveness_percentage'])\n",
    "\n",
    "print(f\"\\nTimeline entries: {len(doc_system.timeline)}\")\n",
    "print(f\"Lessons learned documented: {len(doc_system.lessons_learned)}\")\n",
    "\n",
    "print(\"\\nSUCCESS: Incident documentation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a1bb9",
   "metadata": {},
   "source": [
    "### üìÑ **Incident Documentation System Results**\n",
    "\n",
    "**Documentation is critical for compliance, learning, and legal protection. Here's what was created:**\n",
    "\n",
    "**Documentation Generated:**\n",
    "- **Report ID**: INC-20250804114959 (unique incident identifier)\n",
    "- **Severity**: MEDIUM (final classification after full analysis)  \n",
    "- **Response effectiveness**: 90.0% (excellent containment success)\n",
    "\n",
    "**Key Documentation Components Created:**\n",
    "\n",
    "1. **Timeline entries**: 3 critical events logged\n",
    "   - Incident Detection\n",
    "   - Response Initiated  \n",
    "   - Incident Resolved\n",
    "\n",
    "2. **Lessons learned**: 4 key insights documented\n",
    "   - Response procedures effectiveness\n",
    "   - Detection system performance\n",
    "   - Communication protocol success\n",
    "   - Recovery time assessment\n",
    "\n",
    "**Why Documentation Matters:**\n",
    "- **Legal Protection**: Evidence of due diligence and proper response\n",
    "- **Compliance**: Regulatory requirements (SOX, HIPAA, GDPR, etc.)\n",
    "- **Continuous Improvement**: Learn from each incident to improve security\n",
    "- **Audit Trail**: Complete record for internal and external audits\n",
    "\n",
    "**Professional Context**: In real organizations, incident documentation often determines:\n",
    "- Insurance claim success\n",
    "- Regulatory penalty severity  \n",
    "- Legal liability exposure\n",
    "- Future security budget approval\n",
    "\n",
    "**Success Indicator**: Complete documentation within minutes of resolution demonstrates mature incident response capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display executive summary\n",
    "print(\"EXECUTIVE SUMMARY FOR MANAGEMENT\")\n",
    "print(\"=\" * 34)\n",
    "\n",
    "executive_summary = doc_system.generate_executive_summary()\n",
    "print(executive_summary)\n",
    "\n",
    "print(\"\\nLESSONS LEARNED:\")\n",
    "for i, lesson in enumerate(doc_system.lessons_learned, 1):\n",
    "    print(f\"{i}. {lesson}\")\n",
    "\n",
    "print(\"\\nINCIDENT TIMELINE:\")\n",
    "for entry in doc_system.timeline:\n",
    "    print(f\"{entry['timestamp']}: {entry['event']} - {entry['details']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CRISIS SIMULATION COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final Status: {containment_assessment['containment_status']}\")\n",
    "print(f\"Overall Effectiveness: {containment_assessment['effectiveness_percentage']:.1f}%\")\n",
    "print(f\"Documentation Complete: Report {incident_report['incident_id']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124235a",
   "metadata": {},
   "source": [
    "### üéØ **Complete Incident Response Simulation Summary**\n",
    "\n",
    "**Congratulations! You've successfully completed a full AI security incident response simulation!**\n",
    "\n",
    "## **What You Just Experienced:**\n",
    "\n",
    "### **Executive Summary Highlights:**\n",
    "- **Incident ID**: INC-20250804114959 (your unique incident case study)\n",
    "- **Total Response Time**: ~4 minutes (detection to resolution)\n",
    "- **Final Effectiveness**: 90% (excellent performance)\n",
    "- **Impact**: 100K users protected through rapid response\n",
    "\n",
    "### **Complete Incident Lifecycle:**\n",
    "1. **Detection** ‚Üí AI performance monitoring identified 29% degradation\n",
    "2. **Analysis** ‚Üí Multi-vector threat assessment (performance + data drift)  \n",
    "3. **Classification** ‚Üí MEDIUM severity with MULTIPLE_INDICATORS\n",
    "4. **Response** ‚Üí 4/4 containment actions successful\n",
    "5. **Communication** ‚Üí 9 stakeholder messages across 3 groups\n",
    "6. **Recovery** ‚Üí Model performance restored to 82% (significant improvement)\n",
    "7. **Documentation** ‚Üí Complete incident report with lessons learned\n",
    "\n",
    "## **Real-World Application:**\n",
    "This simulation mirrors actual AI security incidents where:\n",
    "- **Speed is critical** (Golden Hour principle)\n",
    "- **Multiple systems must coordinate** (technical + business + communication)\n",
    "- **Documentation is mandatory** (legal and compliance requirements)\n",
    "- **Continuous improvement** drives better future response\n",
    "\n",
    "## **Key Learning Outcomes:**\n",
    "‚úÖ **Technical Skills**: AI threat detection and analysis  \n",
    "‚úÖ **Process Knowledge**: Incident response procedures  \n",
    "‚úÖ **Communication**: Stakeholder management during crisis  \n",
    "‚úÖ **Documentation**: Compliance and audit trail creation  \n",
    "‚úÖ **Decision Making**: Balancing speed with accuracy under pressure\n",
    "\n",
    "**Professional Value**: You now understand the complete incident response lifecycle that AI security professionals use to protect organizations from sophisticated AI attacks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e03be",
   "metadata": {},
   "source": [
    "### Incident Documentation Importance\n",
    "\n",
    "Comprehensive documentation serves multiple purposes:\n",
    "\n",
    "1. **Legal Requirements**: Many industries require detailed incident records\n",
    "2. **Continuous Improvement**: Analysis enables better future responses\n",
    "3. **Compliance**: Regulatory bodies often require incident reporting\n",
    "4. **Knowledge Transfer**: Helps train future incident responders\n",
    "5. **Insurance Claims**: Detailed records support cyber insurance claims\n",
    "\n",
    "**Best Practice**: Document while responding, not just at the end - details fade quickly from memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81171b73",
   "metadata": {},
   "source": [
    "## üß† Chapter 6 Self-Assessment Quiz\n",
    "\n",
    "Test your understanding of AI incident response procedures and crisis management with our interactive quiz! This comprehensive assessment covers:\n",
    "\n",
    "### üìã **Quiz Coverage**\n",
    "\n",
    "- **Incident Classification**: Severity levels and performance degradation thresholds\n",
    "- **Threat Analysis**: Multi-indicator assessment and data drift detection  \n",
    "- **Response Procedures**: Containment actions and effectiveness measurement\n",
    "- **Crisis Communication**: Stakeholder management and tailored messaging\n",
    "- **Documentation**: Compliance requirements and lessons learned processes\n",
    "- **Professional Concepts**: Golden Hour principle and real-world applications\n",
    "\n",
    "**üìä Quiz Format:** 10 multiple-choice questions with detailed explanations  \n",
    "**‚è±Ô∏è Estimated Time:** 10-15 minutes  \n",
    "**üéØ Difficulty Level:** Intermediate - based on simulation experience  \n",
    "\n",
    "Ready to test your AI incident response knowledge? Run the cell below to launch the interactive quiz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 6 Quiz - Test Your Understanding\n",
    "print(\"üìù Opening Chapter 6 AI Incident Response Quiz...\")\n",
    "\n",
    "import webbrowser\n",
    "import os\n",
    "\n",
    "quiz_file = 'chapter6_quiz.html'\n",
    "file_path = os.path.abspath(quiz_file)\n",
    "webbrowser.open(f'file://{file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38d6c7",
   "metadata": {},
   "source": [
    "## Activity Summary\n",
    "\n",
    "Congratulations! You've successfully led an AI security incident response from detection through resolution. In this exercise, you:\n",
    "\n",
    "‚úÖ **Executed automated threat detection** to identify and classify an AI security incident  \n",
    "‚úÖ **Implemented containment procedures** using AI-specific response techniques  \n",
    "‚úÖ **Managed stakeholder communications** tailored to different audience needs  \n",
    "‚úÖ **Conducted recovery operations** with monitoring and validation  \n",
    "‚úÖ **Generated comprehensive documentation** and lessons learned analysis  \n",
    "\n",
    "### Key Skills Developed:\n",
    "\n",
    "1. **Incident Classification**: Learned to identify different types of AI security threats\n",
    "2. **Automated Response**: Experienced the benefits of automation in incident response\n",
    "3. **Stakeholder Management**: Practiced communicating complex technical issues appropriately\n",
    "4. **Recovery Planning**: Understood the importance of systematic recovery procedures\n",
    "5. **Continuous Improvement**: Gained experience in post-incident analysis and improvement\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Incident Response Planning**: Use this framework to develop IR plans for your AI systems\n",
    "- **Team Training**: Adapt this simulation for training your incident response teams\n",
    "- **Process Improvement**: Apply the lessons learned methodology to enhance your procedures\n",
    "- **Automation Development**: Build automated response capabilities based on this model\n",
    "\n",
    "### Next Steps:\n",
    "- Practice with different incident scenarios (data poisoning, model extraction, privacy breaches)\n",
    "- Develop organization-specific incident response playbooks\n",
    "- Implement automated monitoring and response systems\n",
    "- Conduct regular incident response exercises and tabletop scenarios\n",
    "\n",
    "---\n",
    "\n",
    "**Emergency Response Complete** üö®‚úÖ  \n",
    "*Well done, Incident Commander! Your quick thinking and systematic approach successfully contained the AI security threat.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
